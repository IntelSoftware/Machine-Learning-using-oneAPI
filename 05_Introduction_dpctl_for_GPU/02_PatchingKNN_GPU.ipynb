{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa88ccd5-22db-471f-ace0-d302bf8a476c",
   "metadata": {},
   "source": [
    "# Module 05_02: KNN: targeting GPU and Patching \n",
    "\n",
    "![Assets/GPUTargeted.png](Assets/GPUTargeted.png)\n",
    "### Use nbconvert  patch_sklearn from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758b2cdb-e2c0-4613-bb03-f01e2fe41031",
   "metadata": {},
   "source": [
    "# Learning Objectives:\n",
    "\n",
    "1) Describe how to apply dpctl compute follows data in conjuction with patching\n",
    "1) Apply patching to KNN algorithm on covtype dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5bdd00-2c32-49b1-bd39-77e140e5f739",
   "metadata": {},
   "source": [
    "# *Real World* example KNN on CovType Dataset\n",
    "\n",
    "### Compare timings of stock kmeans versus Intel Extension for Scikit-learn KNN using patch_sklean()\n",
    "\n",
    "Below we will apply Intel Extension for Scikit learn to a use case on a CPU\n",
    "\n",
    "Intel® Extension for Scikit-learn contains drop-in replacement functionality for the stock scikit-learn package. You can take advantage of the performance optimizations of Intel Extension for Scikit-learn by adding just two lines of code before the usual scikit-learn imports. Intel® Extension for Scikit-learn patching affects performance of specific Scikit-learn functionality.\n",
    "\n",
    "### Data: covtype\n",
    "\n",
    "We will use forest cover type dataset known as covtype and fetch the data from sklearn.datasets\n",
    "\n",
    "\n",
    "Here we are **predicting forest cover type** from cartographic variables only (no remotely sensed data). The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data. Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types).\n",
    "\n",
    "This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.\n",
    "\n",
    "\n",
    "Predicting forest cover type from cartographic variables only (no remotely sensed data). The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data. Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types).\n",
    "\n",
    "This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.\n",
    "\n",
    "### Overview of procedure\n",
    "In the below example we will train and predict kNN algorithm with Intel Extension for Scikit-learn for covtype dataset and calculate the CPU and wall clock time for training and prediction. Then in the next step we will unpatch the Intel extension for Scikit-learn and observe the time taken on the CPU for the same trainng and prediction.\n",
    "\n",
    "### Fetch the Data\n",
    "\n",
    "- [Back to Sections](#Back_to_Sections)\n",
    "\n",
    "# Regarding when/how to cast to and from dpctl.tensors\n",
    "\n",
    "This information bears repeating: to make sure the concept is clear.\n",
    "\n",
    "Study the code sectons near the conversion to and from dptcl/Numpy\n",
    "\n",
    "For all sklearnex alogorithms - it will be necessary to cast the X and/or y data passed as the parameter list to dpctl tensor in order for the GPU to access the data and performan the computation.\n",
    "\n",
    "Examples:\n",
    "- **x_device** = dpctl.tensor.from_numpy(**x**, usm_type = 'device', device = dpctl.SyclDevice(\"gpu\"))\n",
    "- **y_device** = dpctl.tensor.from_numpy(**y**, usm_type = 'device', device = dpctl.SyclDevice(\"gpu\"))\n",
    "\n",
    "\n",
    "\n",
    "Pay attention ot **return** types from:\n",
    "- **fit** - many cases in scikit-learn, fit returns selfobject\n",
    "- **fit_predict** - returns **ndarray** requires casting after the call on host (to_numpy)\n",
    "- **predict** -  returns **ndarray** requires casting after the call on host (to_numpy)\n",
    "- **fit_transform** - returns returns **ndarray** requires casting after the call on host (to_numpy)\n",
    "- **tranform** - typically returns **ndarray** requires casting after the call on host (to_numpy)\n",
    "\n",
    "Scikit-learn routines that potentially return ndarray type objects or which expect ndtype objects passed as a parameter will need to be cast to/from numpy from/to dpctl.tensor\n",
    "\n",
    "To cast data being fed TO one of these routines:\n",
    "- use dpctl.tensor.from_numpy() to conver from NumPy to dpctl tensor\n",
    "- use dpctl.tensor.to_numpy() to convert from dpctl tensor to NumPy\n",
    "\n",
    "Example: After a call to fit_predict:\n",
    "- **catch_device** = estimator.fit_predict(**x_device**, **y_device**)\n",
    "- **predictedHost** = dpctl.tensor.to_numpy(**catch_device**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b6234a-b2df-488c-a6b8-83c93b1f3a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T01:44:24.872648Z",
     "start_time": "2021-11-03T01:44:15.236809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/compute_KNN_GPU.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/compute_KNN_GPU.py\n",
    "# Copyright 2022 Intel Corporation\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "############################3 import dpctl #################################\n",
    "import dpctl\n",
    "############################################################################\n",
    "\n",
    "#########  apply patch here  prior to import of desired scikit-learn #######\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "############################################################################\n",
    "\n",
    "\n",
    "from  sklearn.datasets import fetch_covtype\n",
    "x, y = fetch_covtype(return_X_y=True)\n",
    "# Data Set Information:\n",
    "# Predicting forest cover type from cartographic variables only (no remotely sensed data). The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data. Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types).\n",
    "# This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.\n",
    "\n",
    "# for sake of time is 1/4th of the data\n",
    "subset = x.shape[0]//4\n",
    "x = x[:subset,:]\n",
    "y = y[:subset]\n",
    "\n",
    "# Is this computed on GPU or on Host? Remember compute follows data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=72)\n",
    "\n",
    "#########  Add code to get GPU context and set flag if GPU is available   #######\n",
    "#########  Add code to to set CPU context as well so this runs on eiher device   #######\n",
    "#for d in dpctl.get_devices():\n",
    "    # gpu_available = _________\n",
    "    # for d in dpctl.get_devices():\n",
    "        #if d.______:\n",
    "            #gpu_device = __________________\n",
    "            #gpu_available = _______\n",
    "        #else:\n",
    "            #cpu_device = _____________\n",
    "#if gpu_available:\n",
    "    #print(\"GPU targeted: \", ______ )\n",
    "#else:\n",
    "   #print(\"CPU targeted: \", cpu_device)\n",
    "#########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "if gpu_available:\n",
    "    ################## add code to cast from Numpy to dpctl_tensors #########################    # target a remote host GPU when submitted via q.sh or qsub -I\n",
    "    #x_train_device =\n",
    "    #y_train_device = \n",
    "    #x_test_device = \n",
    "    #y_test_device = \n",
    "    ##########################################################################################\n",
    "else:\n",
    "    ################## add code to cast from Numpy to dpctl_tensors for Host CPU ####################    # target a remote host GPU when submitted via q.sh or qsub -I    \n",
    "    # target a remote host CPU when submitted via q.sh or qsub -I\n",
    "    #x_train_device = \n",
    "    #y_train_device =    \n",
    "    #x_test_device = \n",
    "    #y_test_device = \n",
    "    ##########################################################################################\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': 40,  \n",
    "    'weights': 'distance'\n",
    "}\n",
    "print('dataset shape: ', x_train_device.shape)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(**params).fit(x_train_device, y_train_device)\n",
    "\n",
    "predictedGPU = knn.predict(x_test_device) #Predict on GPU\n",
    "#predictedCPU = knn.predict(x_test) #Predict on CPU\n",
    "    \n",
    "################## add code to cast returned results to Numpy to dpctl_tensors ################  \n",
    "# only need to do this for predict. fit_predict, transform, fit_transform IF I need to use results\n",
    "# target a remote host GPU when submitted via q.sh or qsub -I    \n",
    "#  predictedGPUNumpy = \n",
    "# reportGPU = metrics.classification_report(y_test, _________)\n",
    "#print(f\"Classification report for kNN Fit and Predicted on GPU:\\n{reportGPU}\\n\")\n",
    "###############################################################################################\n",
    "\n",
    "reportCPU = metrics.classification_report(y_test, predictedCPU)\n",
    "print(f\"Classification report for kNN Fit on GPU and Predicted on CPU:\\n{reportCPU}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b171b23-3698-460f-bc13-54464dce356d",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "\n",
    "An alternative to the q method below \n",
    "- launch a DevCloud Terminal and squb to a GPU enabled device as follows:\n",
    "- qsub -I -l  nodes=1:gpu:ppn=2\n",
    "- then run the bash script as follows:\n",
    "- . run_KNN_dpctl.sh\n",
    "\n",
    "## Demonstration of speedup without significant loss of accuracy\n",
    "\n",
    "#### For running in this notebook:\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46df347a-d793-43fc-81b7-212ed031f61a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T01:44:24.881650Z",
     "start_time": "2021-11-03T01:44:15.170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "1904134.v-qsvr-1           ...ub-singleuser u78349          00:02:08 R jupyterhub     \n",
      "1904210.v-qsvr-1           run_KNN_dpctl.sh u78349                 0 Q batch          \n",
      "\n",
      "Waiting for Output ████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Wed 11 May 2022 02:43:04 PM PDT\n",
      "#    Job ID:           1904210.v-qsvr-1.aidevcloud\n",
      "#      User:           u78349\n",
      "# Resources:           neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u78349 is compiling AI Essentials Module1 -- scikit-learn-Intelex_Intro - 4 of 5 KNN_dpctl.py\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 1904210.v-qsvr-1.aidevcloud\n",
      "# Date: Wed 11 May 2022 02:43:10 PM PDT\n",
      "########################################################################\n",
      "\n",
      "  File \"/home/u78349/ai_learning_paths/ML_using_oneAPI/ML_using_oneAPI/05_Introduction_dpctl_for_GPU/lab/compute_KNN_GPU.py\", line 69\n",
      "    else:\n",
      "    ^\n",
      "IndentationError: expected an indented block\n",
      "Job Completed in 16 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run_KNN_dpctl.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_KNN_dpctl.sh; else ./run_KNN_dpctl.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd89362-01cd-419f-bf55-eab68dbd2f18",
   "metadata": {},
   "source": [
    "In order to cancel optimizations, we use unpatch_sklearn and reimport the class KNeighborsClassifier. Observe the classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799ebc5a-489b-4c33-8be8-10cb804e250c",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "\n",
    "We observe that with scikit-learn-intelex compute follow data:\n",
    "\n",
    "- Easily target training or prediction on GPU\n",
    "- Easily target training on GPU and prediction on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d68bd-e5e7-40c5-9b6c-1405369057c5",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "You have:\n",
    "\n",
    "1) Applied patching to KNN algorithm\n",
    "2) Applied method to submitt KNN fit to Intel GPU (model on GPU)\n",
    "3) Applied method to submitt KNN predict to Intel GPU (model on GPU)\n",
    "4) Applied method to submitt KNN predict to Intel CPU (model on CPU)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8582307-b7cb-4e39-b0b9-0436f44e24c9",
   "metadata": {},
   "source": [
    "# Notices & Disclaimers \n",
    "\n",
    "Intel technologies may require enabled hardware, software or service activation.\n",
    "No product or component can be absolutely secure.\n",
    "\n",
    "Your costs and results may vary.\n",
    "\n",
    "© Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. \n",
    "*Other names and brands may be claimed as the property of others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
