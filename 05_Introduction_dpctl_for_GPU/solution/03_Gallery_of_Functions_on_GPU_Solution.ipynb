{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4494c78-7e91-407b-833b-87e5c0abd22a",
   "metadata": {},
   "source": [
    "# Module 05_03: Gallery of Functions on GPU\n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "By the end of this lession you will be able to:\n",
    "\n",
    "- Apply the patch functions with varying granularities.\n",
    "- Leverage the Compute Follows Data methodology using Intel DPCTL library to target Intel GPU\n",
    "- In this moduel you will learn **HOW** on an Intel GPU\n",
    "- For the current hardware configurationson the Intel DevCloud - we are **NOT focusing on performance**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db43cf0-b4f1-4cfa-b157-636012eacbb9",
   "metadata": {},
   "source": [
    "**Not all Scikit-learn functions are available yet on Intel GPU**. These are the [currently optimized functions optimized with Intel(R) Extensions for scikit learn](https://intel.github.io/scikit-learn-intelex/algorithms.html). **Pay specific attenstion to the GPU section** Different algorithms have been optimized for Intel CPU and Intel GPU. This allows a develoeprs to check which functions are currently optimized. Some functions are simply aliases to others in that list, to see the 23 optimized \"unique\" functions - open the data/sklearnex_gallery.csv or run the follow cell.\n",
    "\n",
    "**Pandas Gallery of Functions Explorer**\n",
    "Below you can interact with a Pandas Dataframe containing more information obout the algorithms optimized using Intel Extensions for scikit-learn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8115121-0c4c-4c37-a4e1-6dd796349e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sklearnex_gallery_gpu = pd.read_csv('../data/sklearnex_gallery_gpu.csv')\n",
    "sklearnex_gallery_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62ab50-2daf-4e47-aa97-d195857484d8",
   "metadata": {},
   "source": [
    "Below you can filter the dataframe to see details about sklearnex library (aka Intel Extensions to scikit-learn*)\n",
    "\n",
    "- familiarize yourself with a handful of algorithms, explore details aboput 'What is it used for', 'Advantages', 'Disadvantages'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bed106-266a-4496-a5ae-54d1b4553ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gallery_details(acroynm, column):\n",
    "    print(sklearnex_gallery_gpu[sklearnex_gallery_gpu['Acronym'] == acroynm][column].tolist()[0])\n",
    "\n",
    "details = ['What is it used for', 'Advantages', 'Disadvantages']\n",
    "print_gallery_details('kneighborsclassifier', 'Advantages')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd4cf737-2feb-45bf-88de-787cea677098",
   "metadata": {},
   "source": [
    "Import the get_patch_names, get_patch_map from sklearnex and familiarize yourself with the functions available and more detials about where they reise on your system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd87ef8-9ed2-47ef-a70a-9ee764185a48",
   "metadata": {},
   "source": [
    "# Regarding when/how to cast to and from dpctl.tensors\n",
    "\n",
    "This information bears repeating: to make sure the concept is clear.\n",
    "\n",
    "Study the code sectons near the conversion to and from dptcl/Numpy\n",
    "\n",
    "For all sklearnex alogorithms - it will be necessary to cast the X and/or y data passed as the parameter list to dpctl tensor in order for the GPU to access the data and performan the computation.\n",
    "\n",
    "Examples:\n",
    "- **x_device** = dpctl.tensor.from_numpy(**x**, usm_type = 'device', device = dpctl.SyclDevice(\"gpu\"))\n",
    "- **y_device** = dpctl.tensor.from_numpy(**y**, usm_type = 'device', device = dpctl.SyclDevice(\"gpu\"))\n",
    "\n",
    "\n",
    "\n",
    "Pay attention ot **return** types from:\n",
    "- **fit** - many cases in scikit-learn, fit returns selfobject\n",
    "- **fit_predict** - returns **ndarray** requires casting after the call on host (to_numpy)\n",
    "- **predict** -  returns **ndarray** requires casting after the call on host (to_numpy)\n",
    "- **fit_transform** - returns returns **ndarray** requires casting after the call on host (to_numpy)\n",
    "- **tranform** - typically returns **ndarray** requires casting after the call on host (to_numpy)\n",
    "\n",
    "Scikit-learn routines that potentially return ndarray type objects or which expect ndtype objects passed as a parameter will need to be cast to/from numpy from/to dpctl.tensor\n",
    "\n",
    "To cast data being fed TO one of these routines:\n",
    "- use dpctl.tensor.from_numpy() to conver from NumPy to dpctl tensor\n",
    "- use dpctl.tensor.to_numpy() to convert from dpctl tensor to NumPy\n",
    "\n",
    "Example: After a call to fit_predict:\n",
    "- **catch_device** = estimator.fit_predict(**x_device**, **y_device**)\n",
    "- **predictedHost** = dpctl.tensor.to_numpy(**catch_device**)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c397227-d25e-4084-84c6-534d9877431c",
   "metadata": {},
   "source": [
    "# Test Harness\n",
    "\n",
    "Below we create a test harness to test specific comparisons of algorith/parameter choice with specific synthetic data generation choices\n",
    "\n",
    "For measurements, we made a function, \"gallery\",  in which data for each allgorithm is generated, an estiamtor for the algorithms is creaed, the the aggregated training and prediction times are computed.\n",
    "\n",
    "We define a gallery function that will pair one algorithms with a synthesized dataset, to give you a sense of how fast these allgorithms can be when applied to some datasets - Not all datasets will have the same speedups but these are likley typical for the size, shape, and complexity of the generated data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2756d719-5498-447f-9531-224b008e1fd6",
   "metadata": {},
   "source": [
    "# The Gallery Function\n",
    "\n",
    "The below, tests which slearn functiosn are ACTUALLY supported by the given GPU/ version of Intel Extensions for Scikit-learn. Despiste the documentaion on DevCLoud only a handful of algorithms aare supported\n",
    "\n",
    "Keep these pass fail results in mind as you compete the practicums, as you should not blindly submit all algorithms to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc0257-613a-4b0c-8d53-77db24e209cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/gallery_gpu.py\n",
    "from tqdm import tqdm\n",
    "\n",
    "############################# Import dpctl ######################\n",
    "import dpctl\n",
    "##################################################################\n",
    "\n",
    "def gallery(cases):\n",
    "    elapsed_fit = {}  # dictionary to track the time elapsed for the fit method\n",
    "    elapsed_predict = {}  # dictionary to track the time elapsed for the predict/transform method \n",
    "    # the parmeters for this algorithms and for generating the data will be in the next cell\n",
    "    for name, case in tqdm(cases.items()):\n",
    "        print(\"\\nname: \", name)\n",
    "        algorithm = case['algorithm']\n",
    "        try:\n",
    "            estimator = algorithm['estimator'](**algorithm['params'])\n",
    "            data = case['data']\n",
    "            x, y = data['generator'](**data['params'])\n",
    "            x.astype(float)\n",
    "            y.astype(float)\n",
    "            ###################  Add code to get_devices, get_devices, select_gpu_device  ########\n",
    "            for d in dpctl.get_devices():\n",
    "                gpu_available = False\n",
    "                for d in dpctl.get_devices():\n",
    "                    if d.is_gpu:\n",
    "                        gpu_device = dpctl.select_gpu_device()\n",
    "                        gpu_available = True\n",
    "                    else:\n",
    "                        cpu_device = dpctl.select_cpu_device() \n",
    "            if gpu_available:\n",
    "                print(\"GPU targeted: \", gpu_device)\n",
    "            else:\n",
    "                print(\"CPU targeted: \", cpu_device)\n",
    "            ######################################################################################\n",
    "\n",
    "            ############### Add code to convert x & y to dpctl.tensors x_device, y_device #########\n",
    "            x_device = dpctl.tensor.from_numpy(x, usm_type = 'device', device = dpctl.SyclDevice(\"gpu\"))\n",
    "            y_device = dpctl.tensor.from_numpy(y, usm_type = 'device', device = dpctl.SyclDevice(\"gpu\"))\n",
    "            ######################################################################################\n",
    "\n",
    "            if hasattr(estimator, 'fit_predict'):\n",
    "                ###################### Modify code to fit  x_device, y_device ####################\n",
    "                estimator.fit(x_device, y_device)\n",
    "                ##################################################################################\n",
    "                \n",
    "                print(\"fit_predict section\", name,\" fit\")\n",
    "                \n",
    "                ###################### Modify code to predict  x_device, y_device ####################\n",
    "                catch_device = estimator.fit_predict(x_device, y_device)\n",
    "                ######################################################################################\n",
    "                \n",
    "                print(\"fit_predict section\", name,\" fit_predict\")   \n",
    "                \n",
    "                #######################################################################################\n",
    "                ##### Since we will use the prediction to score accuracy metrics, we need to cast it ##\n",
    "                predictedHost = dpctl.tensor.to_numpy(catch_device)\n",
    "                #######################################################################################\n",
    "                \n",
    "                print(\"fit_predict section dpctl.tensor.to_numpy\", name)\n",
    "                print(predictedHost)  \n",
    "            elif hasattr(estimator, 'predict'):\n",
    "                estimator.fit(x_device, y_device)\n",
    "                print(\"predict section\", name, \" fit\")\n",
    "                catch_device = estimator.predict(x_device)\n",
    "                print(\"predict section\", name, \" predict\")\n",
    "                predictedHost = dpctl.tensor.to_numpy(catch_device)\n",
    "                print(\"predict section dpctl.tensor.to_numpy\", name)\n",
    "                print(predictedHost)                             \n",
    "        except Exception as e:\n",
    "            print('A problem has occurred from the Problematic code:\\n', e)\n",
    "            print(\"Not Supported as Configured\\n\\n\")\n",
    "        \n",
    "\n",
    "def get_cases():\n",
    "    return {\n",
    "    'Logistic Regression': {\n",
    "        \"algorithm\": {\n",
    "            'estimator': sklearn.linear_model.LogisticRegression,\n",
    "            'params': {\n",
    "                'random_state': 43,\n",
    "                'max_iter': 300,\n",
    "                'penalty': 'l2'\n",
    "            }\n",
    "        },\n",
    "        \"data\": {\n",
    "            'generator': sklearn.datasets.make_classification,\n",
    "            'params':\n",
    "            {\n",
    "                'n_samples': 10000,\n",
    "                'n_features': 40,\n",
    "                'n_classes': 3,\n",
    "                'n_informative': 5,\n",
    "                'random_state': 43,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'KNN Classifier': {\n",
    "        \"algorithm\": {\n",
    "            'estimator': sklearn.neighbors.KNeighborsClassifier,\n",
    "            'params': {\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        },\n",
    "        \"data\": {\n",
    "            'generator': sklearn.datasets.make_classification,\n",
    "            'params':\n",
    "            {\n",
    "                'n_samples': 3500,\n",
    "                'n_features': 30,\n",
    "                'n_classes': 3,\n",
    "                'n_informative': 3,\n",
    "                'random_state': 43,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'KNN Regression': {\n",
    "        \"algorithm\": {\n",
    "            'estimator': sklearn.neighbors.KNeighborsRegressor,\n",
    "            'params': {\n",
    "                'n_neighbors': 10,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        },\n",
    "        \"data\": {\n",
    "            'generator': sklearn.datasets.make_regression,\n",
    "            'params':\n",
    "            {\n",
    "                'n_samples': 3500,\n",
    "                'n_features': 30,\n",
    "                'n_targets': 1,\n",
    "                'random_state': 43,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'Linear Regression': {\n",
    "        \"algorithm\": {\n",
    "            'estimator': sklearn.linear_model.LinearRegression,\n",
    "            'params': {\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        },\n",
    "        \"data\": {\n",
    "            'generator': sklearn.datasets.make_regression,\n",
    "            'params':\n",
    "            {\n",
    "                'n_samples': 3000,\n",
    "                'n_features': 100,\n",
    "                'n_targets': 1,  \n",
    "                'random_state': 43,\n",
    "            }\n",
    "        }\n",
    "    },     \n",
    "    'dbscan': {\n",
    "            \"algorithm\": {\n",
    "            'estimator': sklearn.cluster.DBSCAN,\n",
    "            'params': {\n",
    "                'eps': 10,\n",
    "                'min_samples' :2\n",
    "            }\n",
    "        },\n",
    "        \"data\": {\n",
    "            'generator': sklearn.datasets.make_blobs,\n",
    "            'params':\n",
    "            {\n",
    "                'n_samples': 3000,  \n",
    "                'n_features': 30,\n",
    "                'centers': 8,\n",
    "                'random_state': 43,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'k_means_random': {\n",
    "            \"algorithm\": {\n",
    "            'estimator': sklearn.cluster.KMeans,\n",
    "            'params': {\n",
    "                'n_clusters': 3,\n",
    "                'random_state' :0, \n",
    "                'init' : 'random',                \n",
    "            }\n",
    "        },\n",
    "        \"data\": {\n",
    "            'generator': sklearn.datasets.make_blobs,\n",
    "            'params':\n",
    "            {\n",
    "                'n_samples': 3000,  \n",
    "                'n_features': 30,\n",
    "                'centers': 8,\n",
    "                'random_state': 43,\n",
    "            }\n",
    "        }\n",
    "    },          \n",
    "}\n",
    "from sklearn import metrics\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()  # this will set parameters such that the stock version of sklearn will be called\n",
    "import sklearn.svm, sklearn.datasets, sklearn.neighbors, sklearn.linear_model, sklearn.decomposition\n",
    "cases = get_cases()  #case the algorithm/dataset pairs\n",
    "gallery(cases)  # call the bench function to captures the elapsed time dictionaries\n",
    "print('All Tests Good\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d6ed33-4583-4b76-8693-f1c262153250",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf490f-e7a1-455a-beb4-3445b61d9eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T01:44:24.881650Z",
     "start_time": "2021-11-03T01:44:15.170Z"
    }
   },
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_gallery_gpu.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_gallery_gpu.sh; else ./run_gallery_gpu.sh; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24677369-c912-415a-a157-b9219dd237d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/TestPCAonGPU.py\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import dpctl\n",
    "\n",
    "x = np.array([[1,1,1],[2,-1,3],[3,2,1]])\n",
    "\n",
    "for d in dpctl.get_devices():\n",
    "    gpu_available = False\n",
    "    for d in dpctl.get_devices():\n",
    "        if d.is_gpu:\n",
    "            gpu_device = dpctl.select_gpu_device()\n",
    "            gpu_available = True\n",
    "        else:\n",
    "            cpu_device = dpctl.select_cpu_device() \n",
    "if gpu_available:\n",
    "    print(\"GPU targeted: \", gpu_device)\n",
    "else:\n",
    "    print(\"CPU targeted: \", cpu_device)\n",
    "\n",
    "pca = PCA(2)\n",
    "\n",
    "x_device = dpctl.tensor.from_numpy(x, usm_type = 'device', device = dpctl.SyclDevice(\"gpu\"))\n",
    "est = pca.fit(x_device)\n",
    "trans_x = pca.transform(x_device)\n",
    "trans_host =  dpctl.tensor.to_numpy(trans_x)\n",
    "print('components_ ', pca.components_)\n",
    "print('explained_variance_ ',pca.explained_variance_)\n",
    "print('transformed x ',trans_host)\n",
    "print('PCA All Good\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c46ea1-bbd0-4bbf-9636-179f6652d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_pca_gpu.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_pca_gpu.sh; else ./run_pca_gpu.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e5657-f37f-41d4-b44c-6fc0e0d18b5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conclusions\n",
    "Only a handful of sklearn algorithms are currently optimized in oneAPI for Intel GPU. It is important to keep your libraries upto date to get the latest versions with themost supported functionality!\n",
    "\n",
    "As you convert each practicum keep this in mind\n",
    "\n",
    "**Exercise:** Take a moment to enumerate the algorithms that you found to be enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9b800-67db-4dbe-9bea-756a4866906d",
   "metadata": {},
   "source": [
    "# Notices & Disclaimers \n",
    "\n",
    "Intel technologies may require enabled hardware, software or service activation.\n",
    "No product or component can be absolutely secure.\n",
    "\n",
    "Your costs and results may vary.\n",
    "\n",
    "© Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. \n",
    "*Other names and brands may be claimed as the property of others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7f42f-e745-4d6e-92cb-ec7de44ce151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
