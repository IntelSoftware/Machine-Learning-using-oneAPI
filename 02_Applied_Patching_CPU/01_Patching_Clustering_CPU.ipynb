{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 02_01: DBSCAN Algorithm Using Intel® Extension for Scikit-learn*\n",
    "\n",
    "![Assets/dbscan.jpg](Assets/dbscan.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Back-to-Sections'></a>\n",
    "\n",
    "\n",
    "You will review, modify and execute code for unsupervised clustering of data using Intel Extension for Scikit-learn for clustering on a single CPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "* Describe the value of Intel® Extension for Scikit-learn methodology in extending scikit-learn optimzation capabilites\n",
    "* Name key imports and function calls to use Intel Extension for Scikit-learn to target DBSCAN\n",
    "* Build a Sklearn implementation of DBSCAN targeting CPU using patching\n",
    "* Apply patching with dynamic versus lexical scope approaches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Intel Extension for Scikit-learn\n",
    "\n",
    "Intel® Extension for Scikit-learn contains drop-in replacement patching functionality for the Scikit-learn machine learning library for Python. The patches were originally available in the daal4py package. All future updates for the patching will be available only in Intel Extension for Scikit-learn. All performance claims obtained using daal4py are applicable for Intel Extension for Scikit-learn.\n",
    "\n",
    "The value of the patch is providing optimized versions of common Scikit-learn machine learning algorithms used for data science. An added value is the ability to invoke these functions on either CPU or GPU.\n",
    "\n",
    "Applying Intel(R) Extension for Scikit-learn will impact the following existing [scikit-learn algorithms:](https://intel.github.io/scikit-learn-intelex/algorithms.html)\n",
    "\n",
    "You can take advantage of the optimizations of Intel Extension for Scikit-learn by adding just two lines of code before the usual Scikit-learn imports:\n",
    "\n",
    " - from sklearnex import patch_sklearn\n",
    " - patch_sklearn()\n",
    " - ...\n",
    " - from sklearn.cluster import DBSCAN\n",
    " - ... import other sklearn algoritms as needed ...\n",
    "\n",
    "Intel Extension for Scikit-learn uses Intel® oneAPI Data Analytics Library (oneDAL) to achieve its acceleration. The optimizations aim for the efficient use of CPU resources. The library enables all the latest vector instructions, such as Intel® Advanced Vector Extensions (Intel AVX-512). It also uses cache-friendly data blocking, fast Basic Linear Algebra Subprograms (BLAS) operations with Intel OneAPI Math Kernel Library (oneMKL), scalable multi-threading with Intel oneAPI Thread Building Blocks (oneTBB) library, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DBSCAN Algorithm\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clustering algorithm used to identify clusters of points in a data set based on the density of the points. It uses two parameters, Epsilon and MinPts, to define clusters. Epsilon determines the maximum distance between two points for them to be considered in the same cluster and MinPts determines the minimum number of points required to form a cluster. DBSCAN starts by randomly selecting a point in the data set and then looking at the Epsilon neighborhood of the point. It then identifies whether the neighborhood is dense enough to form a cluster. If it is, it adds the point to the cluster and continues to search the Epsilon neighborhood of the points in the cluster until no more points can be added. If a point is not part of a dense neighborhood, it is marked as noise. The algorithm is used in a variety of applications including anomaly detection, document clustering, and image segmentation.\n",
    "\n",
    "\n",
    "- [Back to Sections](#Back-to-Sections)\n",
    "\n",
    "### About the data\n",
    "The data included in these exercises was built seperately using the **sklearn.datasets make_blobs** function which synthesizes data for analysis by specifying: \n",
    " - The number of samples in the dataset called n_samples, for example n_sample = 200000\n",
    " - The number of columns in the dataset called n_features, for exmaple n_features = 50,\n",
    " - The number of cluster centers called centers, for example centers = 10, \n",
    " - The standard deviation for each cluster called cluster_std, for example cluster_std = 0.2,\n",
    " - The spatial range over which the clusters range, called center_box for example center_box = (-10.0, 10.0), \n",
    " - A seed called random_state, for example random_state = 777\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Exercise - Experiment with placement of patch:\n",
    " \n",
    " - Apply patching method to ensure that the code uses the optimized DBSCAN from Intel Extensions for scikit-learn*\n",
    "```python\n",
    "from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "patch_sklearn()  \n",
    "```\n",
    ".\n",
    "\n",
    " - Apply patching both within the compute_fit_predict function scope and alternatively: outside the scope of this function. Does patching work in either case? Experiment with lexical versus dynamic extentent of where patch is applied\n",
    " - Ensure one DBSCAN cell is patched, and the other is unpatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions of interest DBSCAN.fit_predict which return ndArray\n",
    "# This cell is running in interactive mode on Jupyter\n",
    "# This allows the leaner to experiment and play\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "def compute_fit_predict():\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    ### Apply patch here alternative 1 ######\n",
    "\n",
    "    #########################################\n",
    "\n",
    "\n",
    "    #from sklearn.cluster import KMeans\n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    #infile = os.path.join('data', 'batch', 'kmeans_dense.csv')\n",
    "    nCentroids = 3\n",
    "\n",
    "    iris = datasets.load_iris()\n",
    "    columns = iris.feature_names\n",
    "    data = iris.data\n",
    "    \n",
    "    ### Apply patch here alternative 2, did this work? ######\n",
    "\n",
    "    #########################################\n",
    "    clustering = DBSCAN(eps=.5, min_samples=2).fit_predict(data)\n",
    "    #kmeans = KMeans(nCentroids, init='random', random_state=0)\n",
    "\n",
    "    #labels = pd.DataFrame( kmeans.fit(data), columns = ['labels'] )\n",
    "    irisDf = pd.DataFrame(data)\n",
    "    clusteringDf = pd.DataFrame(clustering)\n",
    "    df = pd.concat([irisDf, clusteringDf], axis = 1)\n",
    "    df.columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Cluster']    \n",
    "    df.to_csv('clusters.csv', index=False)\n",
    "\n",
    "### Apply patch here alternative 3 #############################################\n",
    "### question if patch is applied here - is it applied BEFORE the import DBSCAN?\n",
    "from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "patch_sklearn()\n",
    "################################################################################\n",
    "\n",
    "compute_fit_predict()\n",
    "clusters = pd.read_csv('clusters.csv')\n",
    "plt.title('clusters - Fit_Predict')\n",
    "plt.scatter(clusters['SepalLength'], clusters['SepalWidth'], s=10, c=clusters['Cluster'], cmap='viridis_r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key learning\n",
    "Patching BEFORE the import implies the dynamic scoping - meaning that the it is applied and a thread of execution encounters the statements\n",
    "\n",
    "So even though, is lexically before the patch (lexically -  as a human would read the code from top to bottom)\n",
    "\n",
    "the patch get applied - because as an execution of code (thread) perspective, the patch is applied, then the function is called and then the import for DBSCAN occurs\n",
    "\n",
    "\n",
    "def compute_fit_predict():\n",
    "...\n",
    "...from sklearn.cluster import DBSCAN\n",
    "...\n",
    "path_sklearn()\n",
    "compute_fit_predict()\n",
    "\n",
    "# Exercise: Apply UNpatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions of interest DBSCAN.fit_predict which return ndArray\n",
    "# This cell is running in interactive mode on Jupyter\n",
    "# This allows the leaner to experiment and play\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "def compute_fit_predict():\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    ### Apply patch here alternative 1 ######\n",
    "\n",
    "    #########################################\n",
    "\n",
    "\n",
    "    #from sklearn.cluster import DBSCAN\n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    #infile = os.path.join('data', 'batch', 'DBSCAN_dense.csv')\n",
    "    nCentroids = 3\n",
    "\n",
    "    iris = datasets.load_iris()\n",
    "    columns = iris.feature_names\n",
    "    data = iris.data\n",
    "    \n",
    "    ### Apply patch here alternative 2, did this work? ######\n",
    "\n",
    "    #########################################\n",
    "    clustering = DBSCAN(eps=.5, min_samples=2).fit_predict(data)\n",
    "    #kmeans = KMeans(nCentroids, init='random', random_state=0)\n",
    "\n",
    "    #labels = pd.DataFrame( kmeans.fit(data), columns = ['labels'] )\n",
    "    irisDf = pd.DataFrame(data)\n",
    "    clusteringDf = pd.DataFrame(clustering)\n",
    "    df = pd.concat([irisDf, clusteringDf], axis = 1)\n",
    "    df.columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Cluster']    \n",
    "    df.to_csv('clusters.csv', index=False)\n",
    "\n",
    "### Apply patch here alternative 3 #############################################\n",
    "### question if patch is applied here - is it applied BEFORE the import DBSCAN?\n",
    "from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "unpatch_sklearn()\n",
    "################################################################################\n",
    "\n",
    "compute_fit_predict()\n",
    "clusters = pd.read_csv('clusters.csv')\n",
    "plt.title('clusters - Fit_Predict')\n",
    "plt.scatter(clusters['SepalLength'], clusters['SepalWidth'], s=10, c=clusters['Cluster'], cmap='viridis_r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this module you will have learned the following:\n",
    "* Able to Name key imports and function calls to use Intel Extension for Scikit-learn to target DBSCAN for use on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notices & Disclaimers \n",
    "\n",
    "Intel technologies may require enabled hardware, software or service activation.\n",
    "No product or component can be absolutely secure.\n",
    "\n",
    "Your costs and results may vary.\n",
    "\n",
    "© Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. \n",
    "*Other names and brands may be claimed as the property of others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "525.6px",
    "left": "28px",
    "top": "137.8px",
    "width": "301.09px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
